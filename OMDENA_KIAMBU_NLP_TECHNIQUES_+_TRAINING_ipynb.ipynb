{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IM_lzb7TqGtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338ab3ba-a734-4213-ac82-beca9211c9ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk #Natural languange Processing tool\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.lancaster import LancasterStemmer #model for stemming words\n",
        "stemmer = LancasterStemmer()\n",
        "# df = pd.read_excel('/content/Omdena Chatbot Dataset.xlsx')\n",
        "# df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbxH48vZ2wNZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f442f1e4-dd69-47a8-e35a-09eaad8768e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import json\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import numpy as num\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import tensorflow as tensorF\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dwphVw8HqOW"
      },
      "outputs": [],
      "source": [
        "ourData ={\"intents\": [\n",
        "        {\"tag\" : \"greeting\",\n",
        "         \"patterns\": [\"Hi\", \"Hi there\", \"Hey\", \"hey\", \"hi\", \"hi there\", \"how are you\", \"How are you\", \"sasa\", \"SaSa\", \"sema\", \"Sema\",\n",
        "            \"Habari\", \"Habari yako\", \"uko aje\", \"Ukoje\", \"hello\", \"Hello\", \"Good evening\", \"Good morning\", \"Good afternoon\",\n",
        "            \"Morning\", \"evening\",     \"afternoon\", \"hello there\", \"Hello there\", \"mambo\", \"Mambo\"],\n",
        "          \"responses\":[\"Hi stranger\", \"poa\", \"Hi too\", \"hi too\", \"hello\", \"Hola\", \"hello, how can I help you?\", \"Poa\", \"Mzuri\",\"mzuri\"]\n",
        "        },\n",
        "        {\"tag\" : \"goodbye\",\n",
        "         \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Ok bye\", \"Bye Bye\", \"bye\", \"bye bye\", \"okay\", \"Okay\",\"wakati mwema\"],\n",
        "         \"responses\" : [\"See you!\", \"Have a nice day\",\"shinda poa\", \"sure bye\", \"Sure byeeeee\", \"Same to you\"]\n",
        "        },\n",
        "        {\"tag\" : \"thanks\",\n",
        "         \"patterns\" : [\"Thanks\", \"Thank you\", \"That was helpful\", \"Awesome\", \"Thanks for your help\", \"asanti\", \"thank you\", \"thank you so much\",\"Nashukuru\"],\n",
        "        \"responses\" : [\"Happy to help\", \"Any time!\",\"my pleasure\",\"You are welcome\", \"Sure, see you then\", \"My Pleasure\", \"Welcome\"]\n",
        "         },\n",
        "         {\"tag\" : \"noanswer\",\n",
        "          \"patterns\" : [],\n",
        "          \"responses\" : [\"Sorry, I can't understand you\", \"Please give me mmore information\",\n",
        "            \"Kindly elaborate on your issue\", \"Provide more information please\", \"Pardon please\", \"Kindly explain more in new terms\"]\n",
        "         },\n",
        "         {\"tag\":\"name\",\n",
        "          \"patterns\":[\"what is your name?\",\"your name please\",\"name please\",\"Your Name please\",\"Can you tell me your name\"],\n",
        "          \"responses\":[\"am PrinceBot\", \"call me PrinceBot\",\"Okay, am PrinceBot\",\"My name is PrinceBot\", \"PrinceBot and what about your name\"]\n",
        "         },\n",
        "        {\"tag\" : \"need\",\n",
        "         \"patterns\" : [\"I am..., I want your help\", \"My name is...,please help\", \"Am called...help me here please\"],\n",
        "         \"responses\": [\"Good to know your name, how can I help you\", \"Great, how can I be of help to you?\", \"Okay, state the issue you want me to help you, please\"]\n",
        "        },\n",
        "\n",
        "        \n",
        "\n",
        "        {\"tag\" : \"options\", \n",
        "\n",
        "         \"patterns\": [\"Can you give me information about DeKUT?\", \"Can you tell me about Dedan Kimathi University of Technology?\",\n",
        "\n",
        "            \"dekut\", \"Dekut\", \"DEKUT\", \"DeKUT\", \"Dedan Kimathi University of Technology\", \"Tell me about DeKUT\", \"What about DeKUT\",\n",
        "\n",
        "            \"How is DeKUT\", \"how is dekut\", \"HOW IS DEKUT\", \"Explain to me about dekut\", \"Explain to me about DeKUT\", \"I want information about DeKUT\", \n",
        "\n",
        "            \"Tell me about Dedan Kimathi University\", \"general information about Dedan Kimathi University\", \"General information about Dedan Kimathi University\", \"General information about Dedan Kimathi University of Technology\"],\n",
        "\n",
        "         \"responses\": [\"Dedan Kimathi University of Technology(DeKUT) is a public, coeducational technological University in Africa-Kenya. First university to be established under the new universities act of 2012 and 8th public university in the country. It has two compuses: Main campus located in Nyeri along Nyahururu-Mweiga road and Nairobi CBD campus. DeKUT offers certificate, diploma, undergraduate, masters and PHD programmes in various field.\" ]\n",
        "\n",
        "        },\n",
        "\n",
        "                             \n",
        "       {\"tag\":\"club\",\n",
        "        \"patterns\":[\"Clubs at Dedan Kimathi University of Technology\",\"clubs at DeKUT\",\"List of clubs at Dedan Kimathi University\",\"How many clubs are at Dedan Kimathi University of Technology\",\"clubs\",\n",
        "            \"Clubs\",\"Give me clubs at Dedan Kimathi University of Technology\",\"Clubs found at DeKUT\"],\n",
        "        \"responses\":[\"International Association Exchange of Students for Technical Experience(IAESTE, Contact)\",\n",
        "                     \"DeKUT Innovators Club(Contact: )\",\n",
        "                     \"Google Developers Students Club_DeKUT (Contact: )\",\n",
        "                     \"DeKUT Ajira Digital Club (Contact: )\",\n",
        "                     \"Data Science and Artificial Intelligence Club (Contact: )\",\n",
        "                     \"Microsoft Learn Students Ambassandors DeKUT Club (Contact: )\"]\n",
        "        \n",
        "        },\n",
        "       {\"tag\" : \"location\",\n",
        "\n",
        "        \"patterns\": [\"Where is DeKUT located\", \"location\", \"how can I find Dedan Kimathi University of Technology\", \"Location of DeKUT.\", \n",
        "\n",
        "            \"location of Dedan Kimathi Universitiy of Technology\", \"Which city is Dedan Kimathi University of Techology found.\", \"where is Dedan Kimathi University of Technology located.\"],\n",
        "\n",
        "         \"responses\" : [\" DeKUT has two campuses:  Main Campus located in Nyeri county,Kenya along Nyahururu-Mweiga highway.  Nairobi CBD Campus located at Pension Towers in Loita Street, nd, th, th floor.\"]\n",
        "\n",
        "        },\n",
        "\n",
        "        \n",
        "\n",
        "       {\"tag\" : \"programmes\",\n",
        "\n",
        "        \"patterns\" :[\"What are the programmes offerred at Dedan Kimathi University of Technology.\", \"Courses offered at DeKUT.\", \"Courses taught at DeKUT\", \"List of courses at Dedan Kimathi University of Technology.\", \n",
        "\n",
        "            \"Courses offered at Dedan Kimathi University of Technology\", \"Courses offered at Dedan Kimathi University.\"],\n",
        "\n",
        "        \"responses\":[\"Dekut offers Postgraduate Programmes ,Undergraduate Programmes,Diploma Courses,Certificate Courses\"]\n",
        "\n",
        "        },\n",
        "\n",
        "       {\"tag\" : \"postgraduate\",\n",
        "\n",
        "        \"patterns\":[\"What are the postgraduate programmes\", \"postgraduate programmes\", \"Postgraduate Programmes\", \"Postgraduate programmes\",\n",
        "\n",
        "            \"Postgraduate programmes offered in DeKUT\",\"PhD courses\",\"masters courses\",\"Masters programmes\",\"Masters courses\"],\n",
        "\n",
        "        \"responses\" : [\"Post graduate programmes currently offered by DEKUT are PhD in Mechanical Engineering, PhD in Geomatics & Geospatial Information Science(GeGIS), PhD in Food Science & Technology,PhD in Computer Science, PhD in Business Administration,Master of Science in Geothermal Energy Technology,Master of Science in Telecommunication Engineering\"]\n",
        "\n",
        "        },\n",
        "       {\"tag\": \"undergraduate\",\n",
        "\n",
        "        \"patterns\":[\"What are the undergraduate programmes\",\"Degree courses\",\"degree courses\",\"undergraduate programmes\",\"Undergradaute programmes\",\n",
        "\n",
        "            \"Undergraduate Programmes\",\"Undergraduate programmes offered in DeKUT\",\"List to me Undergraduate Programmes\",\"Undergraduate courses\"],\n",
        "\n",
        "        \"responses\" :[\"BSc in Mechatronic Engineering\",\"BSc in Mechanical Engineering\",\"BSc in Computer Science\",\"BSc in Acturial Science\",\"BSc in Civil Engineering\", \n",
        "\n",
        "            \"Bachelor in Commerce\",\"Bachelor of Purchasing and Supplies Management\",\"BSc in Geology\",\"BSc in Industrial Chemistry\",\"BSc in Information Technology\",\"BSc in Nursing (Direct Entry)\"]\n",
        "         }\n",
        "]\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9ha40LjJ657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba60016-55ad-4629-e552-90cce6b313c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ll8ljOWuN55T"
      },
      "outputs": [],
      "source": [
        "def _lowercase(obj):\n",
        "    \"\"\" Make dictionary lowercase \"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        return {k.lower():_lowercase(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, (list, set, tuple)):\n",
        "        t = type(obj)\n",
        "        return t(_lowercase(o) for o in obj)\n",
        "    elif isinstance(obj, str):\n",
        "        return obj.lower()\n",
        "    else:\n",
        "        return obj.translate(str.maketrans('', '', string.punctuation))\n",
        "ourData = _lowercase(ourData)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn2Jj00eWr-O"
      },
      "source": [
        "###Creating character/word mappings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUNnEOjnWoqv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "for intent in ourData[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        characters = sorted(list(set(pattern)))\n",
        "        n_to_char = {n:char for n, char in enumerate(characters)}\n",
        "        char_to_n = {char:n for n, char in enumerate(characters)}\n",
        "\n",
        "        X = []\n",
        "        Y = []\n",
        "        length = len(pattern)\n",
        "        seq_length = 100\n",
        "        for i in range(0, length-seq_length, 1):\n",
        "            sequence = ourData[i:i + seq_length]\n",
        "            label =ourData[i + seq_length]\n",
        "            X.append([char_to_n[char] for char in sequence])\n",
        "            Y.append(char_to_n[label])\n",
        "\n",
        "            X_modified = np.reshape(X, (len(X), seq_length, 1))\n",
        "            X_modified = X_modified / float(len(characters))\n",
        "            Y_modified = np_utils.to_categorical(Y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCCfmGagJwCD"
      },
      "outputs": [],
      "source": [
        "lm = WordNetLemmatizer() \n",
        "ourClasses = []\n",
        "newWords = []\n",
        "documentX = []\n",
        "documentY = []\n",
        "\n",
        "for intent in ourData[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        ournewTkns = nltk.word_tokenize(pattern)\n",
        "        newWords.extend(ournewTkns)\n",
        "        documentX.append(pattern)\n",
        "        documentY.append(intent[\"tag\"])\n",
        "\n",
        "\n",
        "    if intent[\"tag\"] not in ourClasses:\n",
        "        ourClasses.append(intent[\"tag\"])\n",
        "\n",
        "newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation] \n",
        "newWords = sorted(set(newWords))\n",
        "ourClasses = sorted(set(ourClasses))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRUCyy2wKhNA"
      },
      "outputs": [],
      "source": [
        "trainingData = [] # training list array\n",
        "outEmpty = [0] * len(ourClasses)\n",
        "# bow model\n",
        "for idx, doc in enumerate(documentX):\n",
        "    bagOfwords = []\n",
        "    text = lm.lemmatize(doc.lower())\n",
        "    for word in newWords:\n",
        "        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n",
        "\n",
        "    outputRow = list(outEmpty)\n",
        "    outputRow[ourClasses.index(documentY[idx])] = 1\n",
        "    trainingData.append([bagOfwords, outputRow])\n",
        "\n",
        "random.shuffle(trainingData)\n",
        "trainingData = num.array(trainingData, dtype=object)\n",
        "\n",
        "x = num.array(list(trainingData[:, 0]))\n",
        "y = num.array(list(trainingData[:, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HWGJ3QdK0LH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1db23d8b-6120-43b6-fafa-4500a7d8704f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               11904     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12)                1548      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,452\n",
            "Trainable params: 13,452\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/200\n",
            "4/4 [==============================] - 2s 15ms/step - loss: 2.3636 - accuracy: 0.1947\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.8758 - accuracy: 0.5310\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.4427 - accuracy: 0.6195\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.0757 - accuracy: 0.7434\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7726 - accuracy: 0.8496\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5553 - accuracy: 0.9115\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.9469\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2935 - accuracy: 0.9558\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2135 - accuracy: 0.9646\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1416 - accuracy: 0.9912\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0920 - accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0800 - accuracy: 0.9912\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0616 - accuracy: 0.9823\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0571 - accuracy: 0.9912\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0374 - accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0441 - accuracy: 0.9912\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0392 - accuracy: 0.9912\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0351 - accuracy: 0.9823\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0195 - accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0292 - accuracy: 0.9823\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0073 - accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0169 - accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0125 - accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0158 - accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9912\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 8.4615e-04 - accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 8.1325e-04 - accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 7.1503e-04 - accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 8.6669e-04 - accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 8.2733e-04 - accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 6.7415e-04 - accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.8642e-04 - accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 9.5170e-04 - accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.4446e-04 - accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 7.1186e-04 - accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.9058e-04 - accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.7994e-04 - accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 7.1276e-04 - accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.1200e-04 - accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 5.9226e-04 - accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 6.5162e-04 - accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 6.3855e-04 - accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 8.0917e-04 - accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1478e-04 - accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 2.9423e-04 - accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 6.8799e-04 - accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 3.2329e-04 - accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 7.6613e-04 - accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 5.1800e-04 - accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.2354e-04 - accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.9611e-04 - accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 9.0498e-04 - accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 7.8720e-04 - accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.8402e-04 - accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.0704e-04 - accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.0105e-04 - accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 9.5157e-04 - accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.6628e-04 - accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.8007e-04 - accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 7.3793e-04 - accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 7.9543e-04 - accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.1488e-04 - accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4.4396e-04 - accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 4.6167e-04 - accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 4.5049e-04 - accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 7.9845e-04 - accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 3.5935e-04 - accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.0407e-04 - accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.7143e-04 - accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 6.6305e-04 - accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.0006e-04 - accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.3303e-04 - accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 4.0424e-04 - accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 4.0704e-04 - accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.0530e-04 - accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.8278e-04 - accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 6.6577e-04 - accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 5.0689e-04 - accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 9.0264e-04 - accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.6644e-04 - accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.7122e-04 - accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 2.5014e-04 - accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 6.5383e-04 - accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 4.1031e-04 - accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3318e-04 - accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.5348e-04 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.4461e-04 - accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 8.4897e-04 - accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.0087e-04 - accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 2.8720e-04 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 6.5904e-04 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.7133e-04 - accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.8715e-04 - accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 8.4414e-04 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 9.4149e-04 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 4.0947e-04 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 4.9877e-04 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.7755e-04 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.6412e-04 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.9735e-04 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 3.2666e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2e1c8aa110>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "iShape = (len(x[0]),)\n",
        "oShape = len(y[0])\n",
        "ourNewModel = Sequential()\n",
        "\n",
        "ourNewModel.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n",
        "ourNewModel.add(Dropout(0.5))\n",
        "ourNewModel.add(Dense(oShape, activation = \"softmax\"))\n",
        "md = tensorF.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
        "ourNewModel.compile(loss='categorical_crossentropy',\n",
        "              optimizer=md,\n",
        "              metrics=[\"accuracy\"])\n",
        "print(ourNewModel.summary())\n",
        "ourNewModel.fit(x, y, epochs=200, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "e6AWl1ywLBH6",
        "outputId": "5b290c04-3e27-46dd-e652-66b23ce2f8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "hello\n",
            "hello, how can i help you?\n",
            "what is yor bane\n",
            "dedan kimathi university of technology(dekut) is a public, coeducational technological university in africa-kenya. first university to be established under the new universities act of 2012 and 8th public university in the country. it has two compuses: main campus located in nyeri along nyahururu-mweiga road and nairobi cbd campus. dekut offers certificate, diploma, undergraduate, masters and phd programmes in various field.\n",
            "what is yout name\n",
            "am princebot\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \"\"\"\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5316734c34fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mourResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mnewMessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mintents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mourClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mourResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mourData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install autocorrect\n",
        "from autocorrect import Speller\n",
        "import string\n",
        "def ourText(text):\n",
        "  spell = Speller()\n",
        "  newtkns = nltk.word_tokenize(spell(text.translate(str.maketrans('', '', string.punctuation))))\n",
        "  newtkns = [lm.lemmatize(word) for word in newtkns]\n",
        "  return newtkns\n",
        "\n",
        "def wordBag(text, vocab):\n",
        "  newtkns = ourText(text)\n",
        "  bagOwords = [0] * len(vocab)\n",
        "  for w in newtkns:\n",
        "    for idx, word in enumerate(vocab):\n",
        "      if word == w:\n",
        "        bagOwords[idx] = 1\n",
        "  return num.array(bagOwords)\n",
        "\n",
        "def Pclass(text, vocab, labels):\n",
        "  bagOwords = wordBag(text, vocab)\n",
        "  ourResult = ourNewModel.predict(num.array([bagOwords]))[0]\n",
        "  newThresh = 0.2\n",
        "  yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n",
        "\n",
        "  yp.sort(key=lambda x: x[1], reverse=True)\n",
        "  newList = []\n",
        "  for r in yp:\n",
        "    newList.append(labels[r[0]])\n",
        "  return newList\n",
        "\n",
        "def getRes(firstlist, fJson):\n",
        "  tag = firstlist[0]\n",
        "  listOfIntents = fJson[\"intents\"]\n",
        "  for i in listOfIntents:\n",
        "    if i[\"tag\"] == tag:\n",
        "      ourResult = random.choice(i[\"responses\"])\n",
        "      break\n",
        "  return ourResult\n",
        "while True:\n",
        "    newMessage = input(\"\")\n",
        "    intents = Pclass(newMessage, newWords, ourClasses)\n",
        "    ourResult = getRes(intents, ourData)\n",
        "    print(ourResult)\n",
        "from gtts import gTTS #Import Google Text to Speech\n",
        "from IPython.display import Audio #Import Audio method from IPython's Display Class\n",
        "tts = gTTS(ourResult) #Provide the string to convert to speech\n",
        "tts.save('1.wav') #save the string converted to speech as a .wav file\n",
        "sound_file = '1.wav'\n",
        "Audio(sound_file, autoplay=True) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdaKoA631HSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038bb7ac-aa2c-499f-8690-93aece991f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 104 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Collecting gTTs\n",
            "  Downloading gTTS-2.2.4-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gTTs) (2.23.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gTTs) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gTTs) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gTTs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gTTs) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gTTs) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gTTs) (2022.6.15)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Installing collected packages: SpeechRecognition, gTTs\n",
            "Successfully installed SpeechRecognition-3.8.1 gTTs-2.2.4\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libaudio2 libout123-0 libportaudio2\n",
            "Suggested packages:\n",
            "  nas alsa-utils jackd oss-compat oss4-base pulseaudio\n",
            "The following NEW packages will be installed:\n",
            "  libaudio2 libout123-0 libportaudio2 mpg123\n",
            "0 upgraded, 4 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 269 kB of archives.\n",
            "After this operation, 922 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libaudio2 amd64 1.9.4-6 [50.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libout123-0 amd64 1.25.10-1 [23.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 mpg123 amd64 1.25.10-1 [130 kB]\n",
            "Fetched 269 kB in 0s (1,037 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libaudio2:amd64.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../libaudio2_1.9.4-6_amd64.deb ...\n",
            "Unpacking libaudio2:amd64 (1.9.4-6) ...\n",
            "Selecting previously unselected package libout123-0:amd64.\n",
            "Preparing to unpack .../libout123-0_1.25.10-1_amd64.deb ...\n",
            "Unpacking libout123-0:amd64 (1.25.10-1) ...\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package mpg123.\n",
            "Preparing to unpack .../mpg123_1.25.10-1_amd64.deb ...\n",
            "Unpacking mpg123 (1.25.10-1) ...\n",
            "Setting up libout123-0:amd64 (1.25.10-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libaudio2:amd64 (1.9.4-6) ...\n",
            "Setting up mpg123 (1.25.10-1) ...\n",
            "update-alternatives: using /usr/bin/mpg123.bin to provide /usr/bin/mpg123 (mpg123) in auto mode\n",
            "update-alternatives: using /usr/bin/mpg123.bin to provide /usr/bin/mp3-decoder (mp3-decoder) in auto mode\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libportaudiocpp0 libpython-all-dev libpython3-all-dev python-all python3-all\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudiocpp0 libpython-all-dev libpython3-all-dev portaudio19-dev\n",
            "  python-all python-all-dev python3-all python3-all-dev\n",
            "0 upgraded, 8 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 126 kB of archives.\n",
            "After this operation, 713 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudiocpp0 amd64 19.6.0-1 [15.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpython3-all-dev amd64 3.6.7-1~18.04 [1,096 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 portaudio19-dev amd64 19.6.0-1 [104 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-all amd64 3.6.7-1~18.04 [1,092 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python3-all-dev amd64 3.6.7-1~18.04 [1,100 B]\n",
            "Fetched 126 kB in 0s (631 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 8.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "(Reading database ... 155714 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libportaudiocpp0_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package libpython-all-dev:amd64.\n",
            "Preparing to unpack .../1-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package libpython3-all-dev:amd64.\n",
            "Preparing to unpack .../2-libpython3-all-dev_3.6.7-1~18.04_amd64.deb ...\n",
            "Unpacking libpython3-all-dev:amd64 (3.6.7-1~18.04) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../3-portaudio19-dev_19.6.0-1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1) ...\n",
            "Selecting previously unselected package python-all.\n",
            "Preparing to unpack .../4-python-all_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all-dev.\n",
            "Preparing to unpack .../5-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python3-all.\n",
            "Preparing to unpack .../6-python3-all_3.6.7-1~18.04_amd64.deb ...\n",
            "Unpacking python3-all (3.6.7-1~18.04) ...\n",
            "Selecting previously unselected package python3-all-dev.\n",
            "Preparing to unpack .../7-python3-all-dev_3.6.7-1~18.04_amd64.deb ...\n",
            "Unpacking python3-all-dev (3.6.7-1~18.04) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1) ...\n",
            "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Setting up libpython3-all-dev:amd64 (3.6.7-1~18.04) ...\n",
            "Setting up python3-all (3.6.7-1~18.04) ...\n",
            "Setting up python-all (2.7.15~rc1-1) ...\n",
            "Setting up python3-all-dev (3.6.7-1~18.04) ...\n",
            "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install SpeechRecognition numpy gTTs sklearn\n",
        "!sudo apt-get install mpg123\n",
        "!sudo apt-get install portaudio19-dev python-all-dev python3-all-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCDYWCXOqtcs"
      },
      "outputs": [],
      "source": [
        "import pyttsx3\n",
        "engine = pyttsx3.init()\n",
        "# convert this text to speech\n",
        "text = \"Python is a great programming language\"\n",
        "engine.say(text)\n",
        "# play the speech\n",
        "engine.runAndWait()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUc3j7z4150g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f7d4c6-788c-460a-c433-00a073638de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is this\n"
          ]
        }
      ],
      "source": [
        "def AutoCorrect(text):\n",
        "  spell = Speller()\n",
        "  correct = spell(text.translate(str.maketrans('', '', string.punctuation)))\n",
        "  return correct\n",
        "\n",
        "print(AutoCorrect(\"whay is rhhis\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install espeak ffmpeg libespeak1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX99gk1qySRU",
        "outputId": "277bc5e2-161d-46a8-8003-2a1fb586130a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [Connecting to security.ub\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.36)] [\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 1,581 B] [Waiting for headers] [Connecting to security.ubu\u001b[0m\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [1 InRelease gpgv 1,581 B] [Waiting for headers] [Waiting for headers] [Wait\u001b[0m\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [85.6 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,105 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,333 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,527 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,304 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,901 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,063 kB]\n",
            "Fetched 12.6 MB in 3s (4,683 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "64 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  espeak-data libsonic0\n",
            "The following NEW packages will be installed:\n",
            "  espeak espeak-data libespeak1 libsonic0\n",
            "0 upgraded, 4 newly installed, 0 to remove and 64 not upgraded.\n",
            "Need to get 1,154 kB of archives.\n",
            "After this operation, 2,816 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsonic0 amd64 0.2.0-6 [13.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 espeak-data amd64 1.48.04+dfsg-5 [934 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libespeak1 amd64 1.48.04+dfsg-5 [145 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 espeak amd64 1.48.04+dfsg-5 [61.6 kB]\n",
            "Fetched 1,154 kB in 1s (1,936 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libsonic0:amd64.\n",
            "(Reading database ... 155758 files and directories currently installed.)\n",
            "Preparing to unpack .../libsonic0_0.2.0-6_amd64.deb ...\n",
            "Unpacking libsonic0:amd64 (0.2.0-6) ...\n",
            "Selecting previously unselected package espeak-data:amd64.\n",
            "Preparing to unpack .../espeak-data_1.48.04+dfsg-5_amd64.deb ...\n",
            "Unpacking espeak-data:amd64 (1.48.04+dfsg-5) ...\n",
            "Selecting previously unselected package libespeak1:amd64.\n",
            "Preparing to unpack .../libespeak1_1.48.04+dfsg-5_amd64.deb ...\n",
            "Unpacking libespeak1:amd64 (1.48.04+dfsg-5) ...\n",
            "Selecting previously unselected package espeak.\n",
            "Preparing to unpack .../espeak_1.48.04+dfsg-5_amd64.deb ...\n",
            "Unpacking espeak (1.48.04+dfsg-5) ...\n",
            "Setting up espeak-data:amd64 (1.48.04+dfsg-5) ...\n",
            "Setting up libsonic0:amd64 (0.2.0-6) ...\n",
            "Setting up libespeak1:amd64 (1.48.04+dfsg-5) ...\n",
            "Setting up espeak (1.48.04+dfsg-5) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS #Import Google Text to Speech\n",
        "from IPython.display import Audio #Import Audio method from IPython's Display Class\n",
        "tts = gTTS(\"lets dekut meet for the weekly meeting update\") #Provide the string to convert to speech\n",
        "tts.save('1.wav') #save the string converted to speech as a .wav file\n",
        "sound_file = '1.wav'\n",
        "Audio(sound_file, autoplay=True) "
      ],
      "metadata": {
        "id": "RzepC3hd09zC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "outputId": "1c066a81-4076-4ddf-d918-8361de81834e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentencepiece sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRyR-gwC1mGl",
        "outputId": "759906cf-95e5-4b59-eaa4-eb824b983eed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 7.8 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 46.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 10.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=03e2c499d7631593d54ce1f69228390987c9c772d023891cee765905355e9ac4\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, sentencepiece, sacremoses\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import *\n",
        "# import transformers\n",
        "model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
        "tokenizer = PegasusTokenizerFast.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
        "\n",
        "def get_paraphrased_sentences(model, tokenizer, sentence, num_return_sequences=5, num_beams=5):\n",
        "  # tokenize the text to be form of a list of token IDs\n",
        "  inputs = tokenizer([sentence], truncation=True, padding=\"longest\", return_tensors=\"pt\")\n",
        "  # generate the paraphrased sentences\n",
        "  outputs = model.generate(\n",
        "    **inputs,\n",
        "    num_beams=num_beams,\n",
        "    num_return_sequences=num_return_sequences,\n",
        "  )\n",
        "  # decode the generated sentences using the tokenizer to get them back to text\n",
        "  return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "sentence = \"Kindly elaborate your issue.\"\n",
        "get_paraphrased_sentences(model, tokenizer, sentence, num_beams=3, num_return_sequences=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIX2cVyO3UDY",
        "outputId": "e99e62f8-dbb8-4bb5-b1f6-85702917874d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
            "Model config PegasusConfig {\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 60,\n",
            "  \"max_position_embeddings\": 60,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/227d9f57dd37c1f4f5be77ccf5f896e7551ec64db897d21c4613d235eb9cc73a.9e93d391568a0e6e2b8408cd2311ebfa97682e0e0bd8b83a631ab7ad40e93905\n",
            "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
            "\n",
            "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at tuner007/pegasus_paraphrase.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/b3949a7257f9b4eaaf4f7785be079d89e4fec7d1c3763a58e6a2743635877d1f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/1ff5597b098cfe2ee6d3b0c4b3e94e549fcb86f2e033146119d1591f6e4c4166.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
            "loading file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/3f72dece4d3fcab1480f78a2c2a1f6ab591bb9b77ec8b049f8faa418bd50526d.f96255d0af339b1faae306ed2925a98f5266a4ebbf793a8bca5107f6e0f876dd\n",
            "loading configuration file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"tuner007/pegasus_paraphrase\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 60,\n",
            "  \"max_position_embeddings\": 60,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/tuner007/pegasus_paraphrase/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d6a784b31cbe212ac3dabbc78bc4e454cf9d8a1b11ff2ef1ba1c7497f2bbfb33.7a3e093739f407bcc025e64dfc5244f91bc573ed4285cba53de90f960cbce58e\n",
            "Model config PegasusConfig {\n",
            "  \"_name_or_path\": \"tuner007/pegasus_paraphrase\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"relu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": true,\n",
            "  \"architectures\": [\n",
            "    \"PegasusForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 16,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 16,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 1,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"length_penalty\": 0.8,\n",
            "  \"max_length\": 60,\n",
            "  \"max_position_embeddings\": 60,\n",
            "  \"model_type\": \"pegasus\",\n",
            "  \"normalize_before\": true,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 8,\n",
            "  \"num_hidden_layers\": 16,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 96103\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Please explain your issue.',\n",
              " 'Please elaborate your issue.',\n",
              " 'Please elaborate your problem.']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob"
      ],
      "metadata": {
        "id": "wm_tZtIP39jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e440c5b-e95f-4bee-f8c0-1a274b218a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "res = TextBlob(\"tell me about dekut\")\n",
        "print(res.sentiment.polarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smQ71m-mHsJ5",
        "outputId": "b21ba012-cc9a-43c3-89c0-865426ab5912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YrHuE4naH_Je"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "OMDENA KIAMBU NLP TECHNIQUES + TRAINING.  ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}