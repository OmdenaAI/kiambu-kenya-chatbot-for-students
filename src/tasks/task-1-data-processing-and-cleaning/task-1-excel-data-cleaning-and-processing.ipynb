{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1K2w8ukgYhB",
    "outputId": "6bd69237-5b84-4c10-a37b-9ebb4b1eecee"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1900\\3023800838.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \"\"\" Import Necessary Modules \n\u001b[0;32m      2\u001b[0m \"\"\"\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m \u001b[1;31m#Natural languange Processing tool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "\"\"\" Import Necessary Modules \n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk #Natural languange Processing tool\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer #model for stemming words\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "\"\"\" Reading the dataset and processing the data\n",
    "\"\"\"\n",
    "df = pd.read_excel('/content/Omdena Chatbot Dataset.xlsx') # chenge path to the location of your file\n",
    "df.where(df['Pattern']!= None, df['Tag'].fillna(method='ffill', inplace=True)) # Fill missing values in the tag column\n",
    "\n",
    "\"\"\" Cleaning the pattern column\n",
    "\"\"\"\n",
    "#A Function for cleaning the file (The Pattern column in it)\n",
    "def text_clean(df):\n",
    "    #Lowercasing all the letters\n",
    "    df['Pattern'] = df['Pattern'].str.lower()\n",
    "    \n",
    "    #Removing punctuations and replacing with a single space\n",
    "    df['Pattern'] = df['Pattern'].str.replace(r'[()!?]', ' ', regex=True)\n",
    "    df['Pattern'] = df['Pattern'].str.replace(r'\\[.*?\\]', ' ', regex=True)\n",
    "    \n",
    "    #Filtering non-alphanumeric characters\n",
    "    df['Pattern'] = df['Pattern'].str.replace(r'[^a-z0-9]', ' ', regex=True)\n",
    "\n",
    "text_clean(df)\n",
    "\n",
    "\"\"\" Extracting features from the data\n",
    "\"\"\"\n",
    "# First, we setup blank variable to hold the features we need.\n",
    "ChatVocab = [] # to hold tokenized unique words of sentences in patterns\n",
    "labels = [] # to hold unique tag names for encoding purposes.\n",
    "docs_X = [] # to hold tokenized list of sentence patterns \n",
    "docs_y = [] # to hold a list of labels associated with docs_X list\n",
    "\n",
    "# Looping through the words in pattern column as we tokenize them\n",
    "for pattern in df.Pattern:\n",
    "    tokenized_words = nltk.word_tokenize(pattern)\n",
    "    ChatVocab.extend(tokenized_words)\n",
    "    docs_X.append(tokenized_words)\n",
    "\n",
    "#Loop through the tags building the output\n",
    "for label in df.Tag:\n",
    "    docs_y.append(label)\n",
    "\n",
    "labels = sorted(set(docs_y)) #Getting labels for encoding\n",
    "\n",
    "\"\"\"Creating root words for our Chatbot Vocabulary\n",
    "\"\"\"\n",
    "#creating a list of root words using our earlier imported stemmer from nltk\n",
    "ChatVocab = [stemmer.stem(word.lower()) for word in ChatVocab]\n",
    "ChatVocabulary = sorted(list(set(ChatVocab)))\n",
    "\n",
    "\n",
    "\"\"\" Data encoding using bag of words and one hot encoding\n",
    "    Treat the unique words in ChatVocabulary as columns. Stem the words in docs_X variable and represent them as rows by \n",
    "    putting a numeric number ' 1 ' where the word in row is inline with the word on column and a \" 0 \" otherwise.\n",
    "\"\"\"\n",
    "#First, setup blank variables to hold training and output data\n",
    "train_matrix_list = []\n",
    "output_matrix_list = []\n",
    "\n",
    "#second, create a list of zeros the length = labels for use in the next step\n",
    "output_empty_label = [0 for _ in range(len(labels))]\n",
    "\n",
    "# Third, loop through docs_X, stem each list, \n",
    "# Use the second for loop to build a list of length = len(ChatVocabulary)\n",
    "# use if statement to check whether the word is in stemmed word of docs_X\n",
    "\n",
    "for number, each_list in enumerate(docs_X):\n",
    "    bow = [] #Bag of Words\n",
    "    stemmed_words = [stemmer.stem(word.lower()) for word in each_list]\n",
    "    \n",
    "    for vocab_word in ChatVocabulary:\n",
    "        if vocab_word in stemmed_words:\n",
    "            bow.append(1)\n",
    "        else:\n",
    "            bow.append(0)\n",
    "        \n",
    "        output_column = output_empty_label[:] #make a copy of the earlier zero list\n",
    "        output_column[labels.index(docs_y[number])] = 1 # set the zero list to 1 for each value of docs_y\n",
    "        \n",
    "        train_matrix_list.append(bow) # building training matrix\n",
    "        output_matrix_list.append(output_column) # building output / predicted class\n",
    "\n",
    "#Fourth, convert the train_matrix_list and output_matrix_list into numpy arrays\n",
    "training_data = np.array(train_matrix_list)\n",
    "output_data = np.array(output_matrix_list)\n",
    "\n",
    "#Visualizing the output\n",
    "print(training_data.shape)\n",
    "print(output_data.shape)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "omdena_chatbot_pre_processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
