{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78536521-ec92-4128-8f78-f2dec79f4368",
   "metadata": {},
   "source": [
    "##### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af5bcca-8636-43a6-b99b-7b849b6b6120",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk #Natural languange Processing tool\n",
    "nltk.download('punkt')\n",
    "from nltk.stem.lancaster import LancasterStemmer #model for stemming words\n",
    "stemmer = LancasterStemmer()\n",
    "import json\n",
    "import string\n",
    "import random\n",
    "import nltk\n",
    "import numpy as num\n",
    "import pickle\n",
    "from tensorflow import keras\n",
    "from autocorrect import Speller\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab651cb-cf09-4168-86ad-1fa9395f7de4",
   "metadata": {},
   "source": [
    "##### JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f18d8690-fbd5-4eb9-95e4-f2e53e16fb64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "the_data ={\"intents\": [\n",
    "        {\"tag\" : \"greeting\",\n",
    "         \"patterns\": [\"Hi\", \"Hi there\", \"Hey\", \"hey\", \"hi\", \"hi there\", \"how are you\", \"How are you\", \"sasa\", \"SaSa\", \"sema\", \"Sema\",\n",
    "            \"Habari\", \"Habari yako\", \"uko aje\", \"Ukoje\", \"hello\", \"Hello\", \"Good evening\", \"Good morning\", \"Good afternoon\",\n",
    "            \"Morning\", \"evening\",     \"afternoon\", \"hello there\", \"Hello there\", \"mambo\", \"Mambo\"],\n",
    "          \"responses\":[\"Hi stranger\", \"poa\", \"Hi too\", \"hi too\", \"hello\", \"Hola\", \"hello, how can I help you?\", \"Poa\", \"Mzuri\",\"mzuri\"]\n",
    "        },\n",
    "        {\"tag\" : \"goodbye\",\n",
    "         \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Ok bye\", \"Bye Bye\", \"bye\", \"bye bye\", \"okay\", \"Okay\",\"wakati mwema\"],\n",
    "         \"responses\" : [\"See you!\", \"Have a nice day\",\"shinda poa\", \"sure bye\", \"Sure byeeeee\", \"Same to you\"]\n",
    "        },\n",
    "        {\"tag\" : \"thanks\",\n",
    "         \"patterns\" : [\"Thanks\", \"Thank you\", \"That was helpful\", \"Awesome\", \"Thanks for your help\", \"asanti\", \"thank you\", \"thank you so much\",\"Nashukuru\"],\n",
    "        \"responses\" : [\"Happy to help\", \"Any time!\",\"my pleasure\",\"You are welcome\", \"Sure, see you then\", \"My Pleasure\", \"Welcome\"]\n",
    "         },\n",
    "         {\"tag\" : \"noanswer\",\n",
    "          \"patterns\" : [],\n",
    "          \"responses\" : [\"Sorry, I can't understand you\", \"Please give me mmore information\",\n",
    "            \"Kindly elaborate on your issue\", \"Provide more information please\", \"Pardon please\", \"Kindly explain more in new terms\"]\n",
    "         },\n",
    "         {\"tag\":\"name\",\n",
    "          \"patterns\":[\"what is your name?\",\"your name please\",\"name please\",\"Your Name please\",\"Can you tell me your name\"],\n",
    "          \"responses\":[\"am PrinceBot\", \"call me PrinceBot\",\"Okay, am PrinceBot\",\"My name is PrinceBot\", \"PrinceBot and what about your name\"]\n",
    "         },\n",
    "        {\"tag\" : \"need\",\n",
    "         \"patterns\" : [\"I am..., I want your help\", \"My name is...,please help\", \"Am called...help me here please\"],\n",
    "         \"responses\": [\"Good to know your name, how can I help you\", \"Great, how can I be of help to you?\", \"Okay, state the issue you want me to help you, please\"]\n",
    "        },\n",
    "\n",
    "        \n",
    "\n",
    "        {\"tag\" : \"options\", \n",
    "\n",
    "         \"patterns\": [\"Can you give me information about DeKUT?\", \"Can you tell me about Dedan Kimathi University of Technology?\",\n",
    "\n",
    "            \"dekut\", \"Dekut\", \"DEKUT\", \"DeKUT\", \"Dedan Kimathi University of Technology\", \"Tell me about DeKUT\", \"What about DeKUT\",\n",
    "\n",
    "            \"How is DeKUT\", \"how is dekut\", \"HOW IS DEKUT\", \"Explain to me about dekut\", \"Explain to me about DeKUT\", \"I want information about DeKUT\", \n",
    "\n",
    "            \"Tell me about Dedan Kimathi University\", \"general information about Dedan Kimathi University\", \"General information about Dedan Kimathi University\", \"General information about Dedan Kimathi University of Technology\"],\n",
    "\n",
    "         \"responses\": [\"Dedan Kimathi University of Technology(DeKUT) is a public, coeducational technological University in Africa-Kenya. First university to be established under the new universities act of 2012 and 8th public university in the country. It has two compuses: Main campus located in Nyeri along Nyahururu-Mweiga road and Nairobi CBD campus. DeKUT offers certificate, diploma, undergraduate, masters and PHD programmes in various field.\" ]\n",
    "\n",
    "        },\n",
    "\n",
    "                             \n",
    "       {\"tag\":\"club\",\n",
    "        \"patterns\":[\"Clubs at Dedan Kimathi University of Technology\",\"clubs at DeKUT\",\"List of clubs at Dedan Kimathi University\",\"How many clubs are at Dedan Kimathi University of Technology\",\"clubs\",\n",
    "            \"Clubs\",\"Give me clubs at Dedan Kimathi University of Technology\",\"Clubs found at DeKUT\"],\n",
    "        \"responses\":[\"International Association Exchange of Students for Technical Experience(IAESTE, Contact)\",\n",
    "                     \"DeKUT Innovators Club(Contact: )\",\n",
    "                     \"Google Developers Students Club_DeKUT (Contact: )\",\n",
    "                     \"DeKUT Ajira Digital Club (Contact: )\",\n",
    "                     \"Data Science and Artificial Intelligence Club (Contact: )\",\n",
    "                     \"Microsoft Learn Students Ambassandors DeKUT Club (Contact: )\"]\n",
    "        \n",
    "        },\n",
    "       {\"tag\" : \"location\",\n",
    "\n",
    "        \"patterns\": [\"Where is DeKUT located\", \"location\", \"how can I find Dedan Kimathi University of Technology\", \"Location of DeKUT.\", \n",
    "\n",
    "            \"location of Dedan Kimathi Universitiy of Technology\", \"Which city is Dedan Kimathi University of Techology found.\", \"where is Dedan Kimathi University of Technology located.\"],\n",
    "\n",
    "         \"responses\" : [\" DeKUT has two campuses:  Main Campus located in Nyeri county,Kenya along Nyahururu-Mweiga highway.  Nairobi CBD Campus located at Pension Towers in Loita Street, nd, th, th floor.\"]\n",
    "\n",
    "        },\n",
    "\n",
    "        \n",
    "\n",
    "       {\"tag\" : \"programmes\",\n",
    "\n",
    "        \"patterns\" :[\"What are the programmes offerred at Dedan Kimathi University of Technology.\", \"Courses offered at DeKUT.\", \"Courses taught at DeKUT\", \"List of courses at Dedan Kimathi University of Technology.\", \n",
    "\n",
    "            \"Courses offered at Dedan Kimathi University of Technology\", \"Courses offered at Dedan Kimathi University.\"],\n",
    "\n",
    "        \"responses\":[\"Dekut offers Postgraduate Programmes ,Undergraduate Programmes,Diploma Courses,Certificate Courses\"]\n",
    "\n",
    "        },\n",
    "\n",
    "       {\"tag\" : \"postgraduate\",\n",
    "\n",
    "        \"patterns\":[\"What are the postgraduate programmes\", \"postgraduate programmes\", \"Postgraduate Programmes\", \"Postgraduate programmes\",\n",
    "\n",
    "            \"Postgraduate programmes offered in DeKUT\",\"PhD courses\",\"masters courses\",\"Masters programmes\",\"Masters courses\"],\n",
    "\n",
    "        \"responses\" : [\"Post graduate programmes currently offered by DEKUT are PhD in Mechanical Engineering, PhD in Geomatics & Geospatial Information Science(GeGIS), PhD in Food Science & Technology,PhD in Computer Science, PhD in Business Administration,Master of Science in Geothermal Energy Technology,Master of Science in Telecommunication Engineering\"]\n",
    "\n",
    "        },\n",
    "       {\"tag\": \"undergraduate\",\n",
    "\n",
    "        \"patterns\":[\"What are the undergraduate programmes\",\"Degree courses\",\"degree courses\",\"undergraduate programmes\",\"Undergradaute programmes\",\n",
    "\n",
    "            \"Undergraduate Programmes\",\"Undergraduate programmes offered in DeKUT\",\"List to me Undergraduate Programmes\",\"Undergraduate courses\"],\n",
    "\n",
    "        \"responses\" :[\"BSc in Mechatronic Engineering\",\"BSc in Mechanical Engineering\",\"BSc in Computer Science\",\"BSc in Acturial Science\",\"BSc in Civil Engineering\", \n",
    "\n",
    "            \"Bachelor in Commerce\",\"Bachelor of Purchasing and Supplies Management\",\"BSc in Geology\",\"BSc in Industrial Chemistry\",\"BSc in Information Technology\",\"BSc in Nursing (Direct Entry)\"]\n",
    "         },\n",
    "\n",
    "        {\"tag\":\"diploma\",\n",
    "         \"patterns\":[\"Give me diploma programmes at Dedan Kimathi University of Technology\",\"diploma programmes\",\"Diploma programmes\",\"What are the diploma programmes offered at DeKUT?\",\"Diploma courses\"],\n",
    "         \"responses\":[\"Diploma in Leather Technology\",\"Diploma in Information Technology\",\"Diploma in Security Management\",\"Diploma in Coffee Technology & Cupping\",\"Diploma in Building Technology\",\"Diploma in Fashion Design and Interior Decoration\"]\n",
    "         },\n",
    "\n",
    "        {\"tag\":\"certificate\",\n",
    "         \"patterns\":[\"Give me certificate programmes at Dedan Kimathi University of Technology\",\"certificate programmes\",\"Certificate programmes\",\"What are the certificate programmes offered at DeKUT?,Certificate courses\"],\n",
    "         \"responses\":[\"Certificate in Information Technology\",\"Certificate in Building Technology\",\"Certificate in Electrical & Electronics & Engineering(Power Option)\",\"Certificate in Coffee Technology & Quality Management\",\"Certificate in Welding,Metal Works & Design\"]\n",
    "         },\n",
    "       \n",
    "        {\"tag\":\"opportunity\",\n",
    "         \"patterns\":[\"What are the opportunities at Dedan Kimathi University of Technology\",\"Opportunites at Dedan Kimathi University of Technology\",\"Any job opportunites at Dedan Kimathi University of Technology\",\n",
    "            \"Jobs at Dedan Kimathi University of Technology\",\"Any Jobs at DeKUT?\",\"Can I get a job at DeKUT\",\"How can I get a job at DeKUT\",\"How can I get employed at Dedan Kimathi University of Technology\",\n",
    "            \"employment at DeKUT\",\"Any Tender at DeKUT\",\"How can I get a tender at Dedan Kimathi University of Technology\"],\n",
    "         \"responses\":[\"Job opportunities, internships and Tenders are always posted on the University website. Kindly check for any open opportunities and apply for one that interest you.\",\n",
    "            \"For Jobs, Internships and Tender available in the institution Kindly check the University website. If any is open, follow the given procedures to apply\"]\n",
    "        },\n",
    "       \n",
    "       {\"tag\":\"club\",\n",
    "        \"patterns\":[\"Clubs at Dedan Kimathi University of Technology\",\"clubs at DeKUT\",\"List of clubs at Dedan Kimathi University\",\"How many clubs are at Dedan Kimathi University of Technology\",\"clubs\",\n",
    "            \"Clubs\",\"Give me clubs at Dedan Kimathi University of Technology\",\"Clubs found at DeKUT\"],\n",
    "        \"responses\":[\"International Association Exchange of Students for Technical Experience(IAESTE, Contact)\",\n",
    "                     \"DeKUT Innovators Club(Contact: )\",\n",
    "                     \"Google Developers Students Club_DeKUT (Contact: )\",\n",
    "                     \"DeKUT Ajira Digital Club (Contact: )\",\n",
    "                     \"Data Science and Artificial Intelligence Club (Contact: )\",\n",
    "                     \"Microsoft Learn Students Ambassandors DeKUT Club (Contact: )\"]\n",
    "        \n",
    "        }\n",
    "]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c11bb-9661-4b14-8d49-a147e7807a71",
   "metadata": {},
   "source": [
    "##### Word Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31174bad-3939-4e6c-aabf-f453abb7c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for intent in the_data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        characters=sorted(list(set(pattern)))\n",
    "        n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "        char_to_n = {char:n for n, char in enumerate(characters)} \n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        length = len(pattern)\n",
    "        seq_length = 100\n",
    "        \n",
    "        for i in range(0, length-seq_length, 1):\n",
    "            sequence = the_data[i:i+seq_length]\n",
    "            label = the_data[i + seq_length]\n",
    "            X.append([char_to_n[char] for char in sequence])\n",
    "            y.append(char_to_n[label])\n",
    "            \n",
    "            X_mod = np.reshape(X, len(X), seq_length,1)\n",
    "            X_mod = X_mod/float(len(characters))\n",
    "            y_mod = np_utils.to_categorical(y)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08308c95-7c2c-456e-b80d-cf0f0c006fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer() \n",
    "ourClasses = []\n",
    "newWords = []\n",
    "documentX = []\n",
    "documentY = []\n",
    "\n",
    "for intent in the_data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        ournewTkns = nltk.word_tokenize(pattern)\n",
    "        newWords.extend(ournewTkns)\n",
    "        documentX.append(pattern)\n",
    "        documentY.append(intent['tag'])\n",
    "        \n",
    "        if intent['tag'] not in ourClasses:\n",
    "            ourClasses.append(intent['tag'])\n",
    "    \n",
    "newWords = [lm.lemmatize(word.lower()) for word in newWords if word not in string.punctuation]\n",
    "newWords = sorted(set(newWords))\n",
    "ourClasses = sorted(set(ourClasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed1cf6a-db17-4169-8314-f67672179d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainingData = [] # training list array\n",
    "outEmpty = [0] * len(ourClasses)\n",
    "\n",
    "# bow model\n",
    "for idx, doc in enumerate(documentX):\n",
    "    bagOfwords = []\n",
    "    text = lm.lemmatize(doc.lower())\n",
    "    \n",
    "    for word in newWords:\n",
    "        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n",
    "    \n",
    "    outputRow = list(outEmpty)\n",
    "    outputRow[ourClasses.index(documentY[idx])] = 1\n",
    "    trainingData.append([bagOfwords, outputRow])\n",
    "\n",
    "random.shuffle(trainingData)\n",
    "trainingData = num.array(trainingData, dtype=object)\n",
    "\n",
    "x = num.array(list(trainingData[:, 0]))\n",
    "y = num.array(list(trainingData[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236dca71-4aac-4c9b-9d75-923c0ae084c0",
   "metadata": {},
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2a4429e-857b-407b-984c-d40c1209a0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               13312     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 14)                1806      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,118\n",
      "Trainable params: 15,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "5/5 [==============================] - 1s 2ms/step - loss: 2.5921 - accuracy: 0.1206\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.0111 - accuracy: 0.5603\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.5996 - accuracy: 0.5957\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1704 - accuracy: 0.7305\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8023 - accuracy: 0.8652\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5633 - accuracy: 0.9220\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.9362\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.9574\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9716\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9645\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9787\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1430 - accuracy: 0.9645\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9645\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9858\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9929\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9858\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0470 - accuracy: 0.9929\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0440 - accuracy: 0.9929\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9787\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0386 - accuracy: 0.9929\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9929\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9929\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 0.9929\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 0.9929\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9929\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9929\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0134 - accuracy: 0.9929\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9929\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9929\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9929\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.1008e-04 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.4634e-04 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.8031e-04 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.1090e-04 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.6594e-04 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.3024e-04 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.3601e-04 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.1387e-04 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.9886e-04 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.2833e-04 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 4.6656e-04 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.5263e-04 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.2934e-04 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.4715e-04 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 8.0307e-04 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.7848e-04 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.0659e-04 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 7.1290e-04 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.2206e-04 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.1528e-04 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6596e-04 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.4904e-04 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 4.2388e-04 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.2518e-04 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.9418e-04 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 7.3408e-04 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 8.4948e-04 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 9.5531e-04 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.0463e-04 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 3.0422e-04 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0695e-04 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.8695e-04 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.6917e-04 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.4286e-04 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.5896e-04 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 5.3752e-04 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 7.6902e-04 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.3650e-04 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.8836e-04 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.5720e-04 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.2072e-04 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 8.8016e-04 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.9397e-04 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.8686e-04 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.7293e-04 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.8830e-04 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 9.0765e-04 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.5588e-04 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.7834e-04 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.6688e-04 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 6.9586e-04 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6670e-04 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.1495e-04 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 6.7331e-04 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0438e-04 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.6517e-04 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.4806e-04 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.2331e-04 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.0200e-04 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 4.2599e-04 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 6.2087e-04 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 5.6122e-04 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.3119e-04 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 3.3473e-04 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 5.3245e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a312bab970>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iShape = (len(x[0]),)\n",
    "oShape = len(y[0])\n",
    "\n",
    "The_Model = Sequential()\n",
    "The_Model.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n",
    "The_Model.add(Dropout(0.5))\n",
    "The_Model.add(Dense(oShape, activation = \"softmax\"))\n",
    "md = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
    "\n",
    "The_Model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=md,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "print(The_Model.summary())\n",
    "The_Model.fit(x, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677fbc10-ca75-4e2f-9ed1-14c07acab6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://889d3446-8b23-48ee-873a-6bf464491b11/assets\n"
     ]
    }
   ],
   "source": [
    "# export model as pickel file\n",
    "pickle.dump(The_Model, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38be3e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "# export model using savemodel\n",
    "The_Model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4034146b-9ec5-47cf-85be-1d9049690503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ourText(text):\n",
    "  spell = Speller()\n",
    "  newtkns = nltk.word_tokenize(spell(text.translate(str.maketrans('', '', string.punctuation))))\n",
    "  newtkns = [lm.lemmatize(word) for word in newtkns]\n",
    "  return newtkns\n",
    "\n",
    "\n",
    "def wordBag(text, vocab):\n",
    "  newtkns = ourText(text)\n",
    "  bagOwords = [0] * len(vocab)\n",
    "  for w in newtkns:\n",
    "    for idx, word in enumerate(vocab):\n",
    "      if word == w:\n",
    "        bagOwords[idx] = 1\n",
    "  return num.array(bagOwords)\n",
    "\n",
    "\n",
    "def Pclass(text, vocab, labels):\n",
    "  bagOwords = wordBag(text, vocab)\n",
    "  ourResult = The_Model.predict(num.array([bagOwords]))[0]\n",
    "  newThresh = 0.2\n",
    "  yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n",
    "\n",
    "  yp.sort(key=lambda x: x[1], reverse=True)\n",
    "  newList = []\n",
    "  for r in yp:\n",
    "    newList.append(labels[r[0]])\n",
    "  return newList\n",
    "\n",
    "def getRes(firstlist, fJson):\n",
    "  tag = firstlist[0]\n",
    "  listOfIntents = fJson[\"intents\"]\n",
    "  for i in listOfIntents:\n",
    "    if i[\"tag\"] == tag:\n",
    "      ourResult = random.choice(i[\"responses\"])\n",
    "      break\n",
    "  return ourResult\n",
    "\n",
    "\n",
    "while True:\n",
    "    newMessage = input(\"\")\n",
    "    intents = Pclass(newMessage, newWords, ourClasses)\n",
    "    ourResult = getRes(intents, the_data)\n",
    "    print(ourResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539bed18-dafb-44e4-9572-7ae97c37dd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7dcd8a-6bc5-47bd-8c26-5741ca769328",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = PegasusForConditionalGeneration.from_pretrained(\"tuner007/pegasus_paraphrase\")\n",
    "pegasus_ = PegasusTokenizerFast.from_pretrained(\"tuner007/pegasus_paraphrase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c6de4-ef5a-44bb-b309-cddc53e4b2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "263930470851f494f0ed2879c35b57985588df20f9e529b86e97dd5eb9ddc466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
